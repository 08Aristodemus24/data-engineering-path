# repository for learning data engineering through projects


# Articles, Videos, Papers, Repositories:
* SQL window functions: https://www.youtube.com/watch?v=Ww71knvhQ-s&pp=ygUUc3FsIHdpbmRvdyBmdW5jdGlvbnM%3D

# Insights:
* Data orchestration uses apache airflow which schedules jobs at a specific cadence for tasks like data ingestion, processing, and transformation
* Skim through these documentation quickly to get a high level overview
AWS S3: https://aws.amazon.com/s3/
PostgreSQL: https://www.postgresql.org/docs/
Airflow: https://airow.apache.org/docs/apache-airowtable/core-concepts/index.html
Project idea: Create an Airow DAG that extracts data from your favorite source (nance, sports, music) and
uploads it to a Data Warehouse (any relational database of your choice)

* Batch processing is just a toolframework to manage growing data and enable us to process them in a scalable manner. Scalable means simply that: a software can handle increased workloads, such as more users or larger datasets, while maintaining performance, a sofware can easily add or remove resources to meet changing demands, and a software remains stable and maintains performance even after a sudden increase in workload. 

